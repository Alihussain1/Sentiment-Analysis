{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "reviews = reviews.lower()\n",
    "reviews = ''.join(char for char in reviews if char not in punctuation)\n",
    "reviews = reviews.split('\\n')\n",
    "\n",
    "##get list of all words\n",
    "allWords = ' '.join(reviews)\n",
    "words = allWords.split()\n",
    "\n",
    "word_counter = Counter(words)\n",
    "sorted_word_counter = sorted(word_counter,key=word_counter.get,reverse=True)\n",
    "word_to_int = {word: indx for indx, word in enumerate(sorted_word_counter,1)}\n",
    "\n",
    "##encoding reviews using word_to_int\n",
    "encoded_reviews = []\n",
    "for rev in reviews:\n",
    "    encoded_reviews.append([word_to_int[word] for word in rev.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the']\n",
      "bromwell  ->  21025\n",
      "high  ->  308\n",
      "Words Count :  6020196\n",
      "Unique Words Count :  74072\n",
      "Encoded Reviews :  25001\n"
     ]
    }
   ],
   "source": [
    "print(words[:10])\n",
    "print(words[0],\" -> \" , word_to_int[words[0]])\n",
    "print(words[1],\" -> \" ,word_to_int[words[1]])\n",
    "print(\"Words Count : \" , len(words))\n",
    "print(\"Unique Words Count : \" , len(word_to_int))\n",
    "print(\"Encoded Reviews : \",len(encoded_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews:  1\n",
      "Maximum review length:  2514\n"
     ]
    }
   ],
   "source": [
    "# outlier review stats\n",
    "review_lens = Counter([len(x) for x in encoded_reviews])\n",
    "print(\"Zero-length reviews: \",review_lens[0])\n",
    "print(\"Maximum review length: \",max(review_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Reviews :  25000\n",
      "Encoded Labels :  25000\n"
     ]
    }
   ],
   "source": [
    "#remove the zero length review\n",
    "#must get index to delete same index from labels\n",
    "zero_length_index = [index  for index,encoded_review in enumerate(encoded_reviews) if len(encoded_review) > 0 ]\n",
    "#[ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "encoded_reviews = [encoded_review for encoded_review in encoded_reviews if len(encoded_review) > 0 ]\n",
    "labels = labels.split('\\n')\n",
    "labels = [label for index,label in enumerate(labels) if index  in zero_length_index]\n",
    "encoded_labels = [1 if label=='positive' else 0 for label in labels]\n",
    "print(\"Encoded Reviews : \",len(encoded_reviews))\n",
    "print(\"Encoded Labels : \",len(encoded_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21025, 308, 6, 3, 1050, 207, 8, 2138, 32, 1, 171, 57, 15, 49, 81, 5785, 44, 382, 110, 140, 15, 5194, 60, 154, 9, 1, 4975, 5852, 475, 71, 5, 260, 12, 21025, 308, 13, 1978, 6, 74, 2395, 5, 613, 73, 6, 5194, 1, 24103, 5, 1983, 10166, 1, 5786, 1499, 36, 51, 66, 204, 145, 67, 1199, 5194, 19869, 1, 37442, 4, 1, 221, 883, 31, 2988, 71, 4, 1, 5787, 10, 686, 2, 67, 1499, 54, 10, 216, 1, 383, 9, 62, 3, 1406, 3686, 783, 5, 3483, 180, 1, 382, 10, 1212, 13583, 32, 308, 3, 349, 341, 2913, 10, 143, 127, 5, 7690, 30, 4, 129, 5194, 1406, 2326, 5, 21025, 308, 10, 528, 12, 109, 1448, 4, 60, 543, 102, 12, 21025, 308, 6, 227, 4146, 48, 3, 2211, 12, 8, 215, 23]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_reviews[:1])\n",
    "print(encoded_labels[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all reviews same size\n",
    "seq_length = 200 \n",
    "def pad_truncate_features(original_features,length):\n",
    "    #define list of (length) size lists filled with 0\n",
    "    features = np.zeros((len(original_features),length),dtype=int)\n",
    "    #add first (length) integers and pad 0's if len(row) < length\n",
    "    for indx, feature in enumerate(original_features):\n",
    "        features[indx, -len(feature):] = np.array(feature)[:length]\n",
    "    return features\n",
    "        \n",
    "#len(pad_truncate_features(encoded_reviews[:1],seq_length)[0])\n",
    "encoded_reviews = pad_truncate_features(encoded_reviews,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set :  20000\n",
      "validation set :  2500\n",
      "train set :  2500\n"
     ]
    }
   ],
   "source": [
    "#create train sets, validate sets, test sets\n",
    "split_idx_train = int(len(encoded_reviews)*0.8) # train : 80%  , test & validation 20%\n",
    "split_idx_validate = int(len(encoded_reviews)*0.9) # test : 10% , validation : 10%\n",
    "\n",
    "train_x, test_x, validate_x = encoded_reviews[:split_idx_train], encoded_reviews[split_idx_train:split_idx_validate], encoded_reviews[split_idx_validate:]\n",
    "train_y, test_y, validate_y = encoded_labels[:split_idx_train], encoded_labels[split_idx_train:split_idx_validate], encoded_labels[split_idx_validate:]\n",
    "\n",
    "print(\"train set : \",len(train_x))\n",
    "print(\"validation set : \",len(validate_x))\n",
    "print(\"train set : \",len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tensor dataset then use dataloader on it\n",
    "train_data = TensorDataset(torch.from_numpy(train_x),torch.from_numpy(np.array(train_y)))\n",
    "validate_data = TensorDataset(torch.from_numpy(validate_x),torch.from_numpy(np.array(validate_y)))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x),torch.from_numpy(np.array(test_y)))\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "validate_loader = DataLoader(validate_data,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test_data,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_dim,num_layers,drop_prob):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.Embeddings = nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.LSTM = nn.LSTM(embedding_dim,hidden_dim,num_layers,batch_first=True,dropout=drop_prob)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self,x,hidden):\n",
    "        x = self.Embeddings(x)\n",
    "        lstm_out, hidden = self.LSTM(x,hidden)\n",
    "        \n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sig(out)\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]\n",
    "        return sig_out, hidden\n",
    "    def init_hidden(self,batch_size):\n",
    "        #TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
